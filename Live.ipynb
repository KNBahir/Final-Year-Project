{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w6GSXA86mznk"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Open the default camera\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'X264')\n",
        "out = cv2.VideoWriter(r\"C:\\Users\\bazil\\Desktop\\Project\\Live_Video\\LIVE.mp4\", fourcc, 20.0, (640, 480))\n",
        "\n",
        "while cap.isOpened():\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        # Display the resulting frame\n",
        "        cv2.imshow('frame', frame)\n",
        "        \n",
        "        # Write the frame to the output file\n",
        "        out.write(frame)\n",
        "        \n",
        "        # Press 'q' to exit\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    else:\n",
        "        break\n",
        "\n",
        "# Release everything when done\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dPnN1ML6mznp"
      },
      "outputs": [],
      "source": [
        "input_video_file_path=(r\"C:\\Users\\bazil\\Desktop\\Project\\Live_Video\\LIVE.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the height and width to which each video frame will be resized in our dataset.\n",
        "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
        "\n",
        "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
        "SEQUENCE_LENGTH = 20\n",
        "\n",
        "# Specify the list containing the names of the classes used for training. Feel free to choose any set of classes.\n",
        "CLASSES_LIST = [\"Violence\",\"NonViolence\",\"Fire\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model from disk\n",
        "LRCN_model = load_model(r\"C:\\Users\\bazil\\Desktop\\Project\\LRCN_Model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sVSMScQJmznp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "from email.mime.base import MIMEBase\n",
        "from email import encoders\n",
        "import cv2\n",
        "import numpy as np\n",
        "from playsound import playsound\n",
        "\n",
        "def predict_single_action(video_file_path, SEQUENCE_LENGTH):\n",
        "    '''\n",
        "    This function will perform single action recognition prediction on a video using the LRCN model.\n",
        "    Args:\n",
        "    video_file_path:  The path of the video stored in the disk on which the action recognition is to be performed.\n",
        "    SEQUENCE_LENGTH:  The fixed number of frames of a video that can be passed to the model as one sequence.\n",
        "    '''\n",
        "\n",
        "    # Initialize the VideoCapture object to read from the video file.\n",
        "    video_reader = cv2.VideoCapture(video_file_path)\n",
        "\n",
        "    # Get the width and height of the video.\n",
        "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Declare a list to store video frames we will extract.\n",
        "    frames_list = []\n",
        "    \n",
        "    # Initialize a variable to store the predicted action being performed in the video.\n",
        "    predicted_class_name = ''\n",
        "\n",
        "    # Get the number of frames in the video.\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calculate the interval after which frames will be added to the list.\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
        "\n",
        "    # Iterating the number of times equal to the fixed length of sequence.\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        # Set the current frame position of the video.\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "        # Read a frame.\n",
        "        success, frame = video_reader.read() \n",
        "\n",
        "        # Check if frame is not read properly then break the loop.\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Resize the Frame to fixed Dimensions.\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "        \n",
        "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1.\n",
        "        normalized_frame = resized_frame / 255\n",
        "        \n",
        "        # Appending the pre-processed frame into the frames list\n",
        "        frames_list.append(normalized_frame)\n",
        "\n",
        "    # Passing the  pre-processed frames to the model and get the predicted probabilities.\n",
        "    predicted_labels_probabilities = LRCN_model.predict(np.expand_dims(frames_list, axis = 0))[0]\n",
        "\n",
        "    # Get the index of class with highest probability.\n",
        "    predicted_label = np.argmax(predicted_labels_probabilities)\n",
        "\n",
        "    # Get the class name using the retrieved index.\n",
        "    predicted_class_name = CLASSES_LIST[predicted_label]\n",
        "#     confidence = format(predicted_labels_probabilities[predicted_label])\n",
        "#     confidence_percent = round(confidence * 100, 2)\n",
        "    confidence = predicted_labels_probabilities[predicted_label]\n",
        "    confidence_float = float(confidence)\n",
        "    confidence_percent = round(confidence_float * 100, 2)\n",
        "    \n",
        "    # If the predicted class is Violence, send an email with the video attachment.\n",
        "    if predicted_class_name == 'Violence':\n",
        "\n",
        "        print(\"Sending email...\")\n",
        "           \n",
        "        sound_file_path = \"C:\\\\Users\\\\bazil\\\\Desktop\\\\Project\\\\beep-warning-6387.mp3\"\n",
        "        playsound(sound_file_path)\n",
        "\n",
        "        print(\"Alert sound PLayed.\")\n",
        "\n",
        "        # email credentials\n",
        "        EMAIL_ADDRESS = 'finalyrproject23@gmail.com'\n",
        "        EMAIL_PASSWORD = 'gubjkajaztkdmtty'\n",
        "        RECEIVER_ADDRESS = 'bahirofficial@gmail.com'\n",
        "\n",
        "        # message details\n",
        "        subject = 'Warning: Violence detected in video'\n",
        "        body = f'A video containing violent content has been detected. Confidence: {confidence_percent}%'\n",
        "\n",
        "        # create message\n",
        "        message = MIMEMultipart()\n",
        "        message['From'] = EMAIL_ADDRESS\n",
        "        message['To'] = RECEIVER_ADDRESS\n",
        "        message['Subject'] = subject\n",
        "\n",
        "        # add message body\n",
        "        message.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "        # attach video file\n",
        "        attachment = open(input_video_file_path, 'rb')\n",
        "        video_mime = MIMEBase('application', 'octet-stream')\n",
        "        video_mime.set_payload((attachment).read())\n",
        "        encoders.encode_base64(video_mime)\n",
        "        video_mime.add_header('Content-Disposition', \"attachment; filename= %s\" % os.path.basename(input_video_file_path))\n",
        "        message.attach(video_mime)\n",
        "        \n",
        "        to_addrs = RECEIVER_ADDRESS.split(',')\n",
        "        # send email\n",
        "        session = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        session.starttls()\n",
        "        session.login(EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
        "        text = message.as_string()\n",
        "        session.sendmail(EMAIL_ADDRESS,to_addrs , text)\n",
        "        session.quit()\n",
        "\n",
        "        print(\"Email sent.\")\n",
        "    elif predicted_class_name == 'Fire':\n",
        "        \n",
        "        print(\"Sending email...Fire\")\n",
        "\n",
        "        sound_file_path = \"C:\\\\Users\\\\bazil\\\\Desktop\\\\Project\\\\beep-warning-6387.mp3\"\n",
        "        playsound(sound_file_path)\n",
        "\n",
        "        print(\"Alert sound PLayed.\")\n",
        "\n",
        "\n",
        "        # email credentials\n",
        "        EMAIL_ADDRESS = 'finalyrproject23@gmail.com'\n",
        "        EMAIL_PASSWORD = 'gubjkajaztkdmtty'\n",
        "        RECEIVER_ADDRESS = 'ridha.isha20@gmail.com,maiseridha@gmail.com,bahirofficial@gmail.com'\n",
        "        \n",
        "        # message details\n",
        "        subject = 'Warning: Fire detected in video'\n",
        "        body = f'A video containing Fire has been detected. Confidence: {confidence_percent}%'\n",
        "\n",
        "        # create message\n",
        "        message = MIMEMultipart()\n",
        "        message['From'] = EMAIL_ADDRESS\n",
        "        message['To'] = RECEIVER_ADDRESS\n",
        "        message['Subject'] = subject\n",
        "\n",
        "        # add message body\n",
        "        message.attach(MIMEText(body, 'plain'))\n",
        "\n",
        "        # attach video file\n",
        "        attachment = open(input_video_file_path, 'rb')\n",
        "        video_mime = MIMEBase('application', 'octet-stream')\n",
        "        video_mime.set_payload((attachment).read())\n",
        "        encoders.encode_base64(video_mime)\n",
        "        video_mime.add_header('Content-Disposition', \"attachment; filename= %s\" % os.path.basename(input_video_file_path))\n",
        "        message.attach(video_mime)\n",
        "        \n",
        "        to_addrs = RECEIVER_ADDRESS.split(',')\n",
        "        # send email\n",
        "        session = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "        session.starttls()\n",
        "        session.login(EMAIL_ADDRESS, EMAIL_PASSWORD)\n",
        "        text = message.as_string()\n",
        "        session.sendmail(EMAIL_ADDRESS,to_addrs , text)\n",
        "        session.quit()\n",
        "\n",
        "        print(\"Email sent.\")\n",
        "    else:\n",
        "        print(f'Action Predicted: {predicted_class_name}\\nConfidence: {predicted_labels_probabilities[predicted_label]}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IqpLhmsTmznt",
        "outputId": "7eadb710-70ad-4ad3-c130-88a2c553f09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002708440C280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "Sending email...\n",
            "Alert sound PLayed.\n",
            "Email sent.\n"
          ]
        }
      ],
      "source": [
        "predict_single_action(input_video_file_path, SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
